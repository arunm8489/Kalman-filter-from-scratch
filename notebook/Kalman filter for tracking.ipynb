{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from filter import Kalman\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kalman():\n",
    "    def __init__(self,dt,U,std):\n",
    "\n",
    "        #dt: time intravel in which readings taken\n",
    "        #U: acceleration in x and y direction [ux,uy] as list\n",
    "        #std : variance in x direction,y direction, and variance in acceleration as list [std_x,std_y,std_acc]\n",
    "\n",
    "\n",
    "        # initialize [[px,py,vx,vy]] as zero\n",
    "        self.X = np.zeros(shape=(4,1))\n",
    "        self.U = np.array(U).reshape(2,-1)\n",
    "        self.dt = dt\n",
    "        # error in measurements x and y (ie, std deviation of measurements)\n",
    "        self.xm_std,self.ym_std,self.std_acc = std[0],std[1],std[2]\n",
    "\n",
    "        # Define the State Transition Matrix A\n",
    "        self.A = np.array([[1, 0, self.dt, 0],\n",
    "                            [0, 1, 0, self.dt],\n",
    "                            [0, 0, 1, 0],\n",
    "                            [0, 0, 0, 1]])\n",
    "        # input control matrix\n",
    "        self.B = np.array([[(self.dt**2)/2, 0],\n",
    "                            [0, (self.dt**2)/2],\n",
    "                            [self.dt,0],\n",
    "                            [0,self.dt]])\n",
    "\n",
    "        # since we are tracking only position of a moving object we have (we are not tracking velocity)\n",
    "        self.H = np.array([[1,0,0,0],[0,1,0,0]])\n",
    "\n",
    "        #process covariance matric  # for now we initialize as an identity matrix\n",
    "        self.P = np.eye(self.A.shape[0])\n",
    "\n",
    "        #process noise covariance matrix  // Dynamic noise\n",
    "        #standard deviation of position as the standard deviation of acceleration multiplied by dt**2/2\n",
    "        self.Q = np.array([[(self.dt**4)/4, 0, (self.dt**3)/2, 0],\n",
    "                            [0, (self.dt**4)/4, 0, (self.dt**3)/2],\n",
    "                            [(self.dt**3)/2, 0, self.dt**2, 0],\n",
    "                            [0, (self.dt**3)/2, 0, self.dt**2]]) * self.std_acc**2\n",
    "\n",
    "        #measurement noise covariance matrix  // Measurement noise\n",
    "        self.R = np.array([[self.xm_std**2,0],\n",
    "                           [0, self.ym_std**2]])\n",
    "\n",
    "        self.process_noise = 0\n",
    "        self.measurement_noise = 0\n",
    "\n",
    "        \n",
    "    def predict(self):\n",
    "        \n",
    "        # predict the distance and velocity\n",
    "        self.X = np.dot(self.A,self.X) + np.dot(self.B,self.U) + self.process_noise\n",
    "\n",
    "        # predicted process cov matrix\n",
    "        self.P = np.dot(np.dot(self.A,self.P),self.A.T) + self.Q\n",
    "        \n",
    "        return self.X[0:2]\n",
    "\n",
    "    def update(self,Xm):\n",
    "        Xm = np.array(Xm).reshape(2,1)\n",
    "        \n",
    "        # calculate kalaman gain\n",
    "        # K = P * H'* inv(H*P*H'+R)\n",
    "        denominator = np.dot(self.H,np.dot(self.P,self.H.T)) + self.R\n",
    "        K = np.dot(np.dot(self.P, self.H.T), np.linalg.inv(denominator)) #shape: (4,2)\n",
    "        \n",
    "\n",
    "        # measurments\n",
    "        C = np.eye(Xm.shape[0])\n",
    "        Xm = np.dot(C,Xm) + self.measurement_noise\n",
    "\n",
    "        # update the predicted_state to get final prediction of iteration and process_cov_matrix\n",
    "        self.X = self.X + np.dot(K,(Xm - np.dot(self.H,self.X)))\n",
    "\n",
    "        #update process cov matrix\n",
    "        self.P = (np.eye(K.shape[0]) - np.dot(np.dot(K,self.H),self.P))\n",
    "\n",
    "\n",
    "\n",
    "        return self.X[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_object(img):\n",
    "    # convert to grayscale\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # detecting ball using canny edge detector\n",
    "    edges = cv2.Canny(img,30,200)\n",
    "    \n",
    "    # thresolding image to two values. Those values above 254 is given as 255 and rest 0\n",
    "    ret, edges = cv2.threshold(edges,254,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    # detect countors from this image\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Set the accepted minimum & maximum radius of a detected object\n",
    "    min_radius_thresh= 3\n",
    "    max_radius_thresh= 100   \n",
    "    centers=[]\n",
    "    for c in contours:\n",
    "        # ref: https://docs.opencv.org/trunk/dd/d49/tutorial_py_contour_features.html\n",
    "        (x, y), radius = cv2.minEnclosingCircle(c)\n",
    "        radius = int(radius)\n",
    "        #Take only the valid circles\n",
    "        if (radius > min_radius_thresh) and (radius < max_radius_thresh):\n",
    "            centers.append(np.array([[x], [y]]))\n",
    "            \n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.2) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3c6d04469d3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Read frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVideoCap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mcenters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;31m# If centroids are detected then track them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcenters\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-41385c520317>\u001b[0m in \u001b[0;36mdetect_object\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdetect_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# convert to grayscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# detecting ball using canny edge detector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.1.2) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "KF = Kalman(dt=0.1, U=[1, 1], std=[0.1,0.1,1])\n",
    "VideoCap = cv2.VideoCapture('ball.mp4')\n",
    "\n",
    "while(True):\n",
    "    # Read frame\n",
    "    ret, frame = VideoCap.read()\n",
    "    centers = detect_object(frame)\n",
    "    # If centroids are detected then track them\n",
    "    if (len(centers) > 0):\n",
    "        # Draw the detected circle\n",
    "        cv2.circle(frame, (int(centers[0][0]), int(centers[0][1])), 27, (0, 191, 255), 2)\n",
    "        \n",
    "        #predict the object\n",
    "        (x,y) = KF.predict()\n",
    "        \n",
    "        cv2.rectangle(frame, (x - 30, y - 30), (x + 30, y + 30), (255, 0, 0), 2)\n",
    "        # Update\n",
    "        (x1, y1) = KF.update(centers[0])\n",
    "        # Draw a rectangle as the estimated object position\n",
    "        cv2.rectangle(frame, (x1 - 30, y1 - 30), (x1 + 30, y1 + 30), (0, 0, 255), 2)\n",
    "        \n",
    "        cv2.putText(frame, \"Final Estimated Position\", (x1 + 15, y1 + 10), 0, 0.5, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, \"Predicted Position\", (x + 15, y), 0, 0.5, (255, 0, 0), 2)\n",
    "        cv2.putText(frame, \"Measured Position\", (centers[0][0] + 15, centers[0][1] - 15), 0, 0.5, (0,191,255), 2)\n",
    "        \n",
    "        cv2.imshow('image', frame)\n",
    "        if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "            VideoCap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break    \n",
    "            \n",
    "        cv2.waitKey(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
